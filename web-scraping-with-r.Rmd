---
title: "Web Scraping in R"
subtitle: ""  
author: 
  - "Dr. Matthew Hendrickson"
date: '`r Sys.Date()`'
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: xaringan-themer.css
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE, echo = FALSE)
library(tidyverse)
library(robotstxt)
library(rvest)
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)
style_duo_accent_inverse(
  primary_color = "#035AA6",
  secondary_color = "#03A696"
)
```

name: fix

# ITEMS TO FIX:

1. Author
2. Rating Count (works, clean it up)
3. Scraping Methods
4. Data Assembly

---

name: topics

# Topics

### Ensure these are updated

1. About Me
2. Robots.txt
3. HTML Structure
4. A Little Help with CSS
5. Scraping Methods
6. Scraping
7. Assembling

---

name: about_me

# About Me

- Social Scientist by Training
     - Psychology & Music `%>%`
     - More Psychlogy `%>%`
     - Law & Policy
- Higher Education Analyst by Trade
- R User by Stumbling
     - Excel `%>%`
     - SPSS GUI `%>%`
     - SPSS Syntax `%>%`
     - SQL `%>%`
     - R

---

name: robots_txt

# Robots.txt

##### Always ensure you check the robots.txt file! This assures you are not breaking the terms of service by scraping the site.

```{r robots, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
paths_allowed(paths = c("https://netflix.com/"))
```

---

name: html_structure
class: inverse, center, middle

# HTML

### Basic Structure

---

name: html_diagram
class: inverse, center, middle

background-image: url(web-scraping-with-r_files/html-structure.png)

???

Image credit: [Professor Shawn Santo](http://www2.stat.duke.edu/~fl35/teaching/440-19F/decks/webscraping2.html#3)

---

name: selector_gadget

# A Little Help with CSS

If you aren't familiar with CSS, extracting parts of a website can be daunting.

SelectorGadget is incredibly helpful for this purpose.

<https://selectorgadget.com/>

* This is a Chrome only extension. Another option is to inspect the page elements.


---

name: scraping_header
class: inverse, center, middle

# Web Scraping

---

name: scraping

# Determine a website to scrape

### It only seems appropriate to pull data from Amazon regarding R books

##### Ensure we can scrape the site

```{r robots_amazon, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
paths_allowed(paths = c("https://amazon.com/"))
```

---

name: scraping_amazon

# Setting the URLs

### Before you can get started, you must specific the URLs to pass to the function.

```{r amazon_html, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
amazon_pg_1 <- read_html("https://www.amazon.com/s?k=R&i=stripbooks&rh=n%3A283155%2Cn%3A75%2Cn%3A13983&dc&qid=1592086532&rnid=1000&ref=sr_nr_n_1")
# amazon_pg_2 <- read_html("https://www.amazon.com/s?k=R&i=stripbooks&rh=n%3A283155%2Cn%3A75%2Cn%3A13983&dc&page=2&qid=1592086539&rnid=1000&ref=sr_pg_2")
```

---

name: scraping_amazon_titles

### Scraping Book Titles

```{r amazon_title, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
amazon_pg_1 %>% 
  html_nodes(".s-line-clamp-2") %>% 
  html_text() -> amazon_titles_pg_1
head(amazon_titles_pg_1)
```

---

name: scraping_amazon_titles_clean

### The titles have a great deal of white space and breaks (\n), these need to be removed

```{r amazon_title_clean, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
amazon_titles_pg_1 <- str_trim(amazon_titles_pg_1) # Removes leading & training space
head(amazon_titles_pg_1)
```

---

name: scraping_amazon_author

### Get the book author(s)

```{r amazon_author, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
amazon_pg_1 %>% 
#  html_nodes("a.a-size-base.a-link-normal") %>% 
  html_nodes("div.a-row.a-size-base.a-color-secondary") %>% 
  html_text() %>% 
  str_trim() -> amazon_authors_pg_1
head(amazon_authors_pg_1)
```

---

name: scraping_amazon_format

### Get the book format

```{r format, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
amazon_pg_1 %>% 
  html_nodes("a.a-size-base.a-link-normal.a-text-bold") %>% 
  html_text() %>% 
  str_trim() -> amazon_format_pg_1
head(amazon_format_pg_1)
```

---

name: scraping_amazon_price

### Get the book price

```{r price_whole, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
amazon_pg_1 %>% 
  html_nodes(".a-price-whole") %>% 
  html_text() -> amazon_price_whole_pg_1
head(amazon_price_whole_pg_1)
```

##### Get (the rest of) the book price

```{r price_fraction, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
amazon_pg_1 %>% 
  html_nodes(".a-price-fraction") %>% 
  html_text() -> amazon_price_fraction_pg_1
head(amazon_price_fraction_pg_1)
```

##### Combine price portions

```{r price_total, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
amazon_price_pg_1 <- as.numeric(paste(amazon_price_whole_pg_1, amazon_price_fraction_pg_1, sep = ""))
head(amazon_price_pg_1)
```

---

name: scraping_amazon_rating

### Get the book rating

```{r rate, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
amazon_pg_1 %>% 
  html_nodes("i.a-icon.a-icon-star-small.a-star-small-4-5.aok-align-bottom") %>% 
  html_text() -> amazon_rating_pg_1
head(amazon_rating_pg_1)
```

```{r rate_trim, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
amazon_rating_pg_1 <- as.numeric(substr(amazon_rating_pg_1, 1, 3))
head(amazon_rating_pg_1)
```

---

name: scraping_amazon_num_ratings

### Get the book rating count

```{r rate_n, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
amazon_pg_1 %>% 
#  html_nodes("span.a-size-base") %>% 
  html_nodes("div.a-row.a-size-small") %>% 
  html_text() -> amazon_rate_n_pg_1
amazon_rate_n_pg_1 <- str_trim(amazon_rate_n_pg_1)
amazon_rate_n_pg_1 <- str_sub(amazon_rate_n_pg_1, -5)
amazon_rate_n_pg_1 <- str_trim(amazon_rate_n_pg_1)
amazon_rate_n_pg_1 <- as.numeric(amazon_rate_n_pg_1)
head(amazon_rate_n_pg_1)
```

---

name: scraping_amazon_pub_date

### Get the book publication date

```{r pub_dt, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
amazon_pg_1 %>% 
  html_nodes("span.a-size-base.a-color-secondary.a-text-normal") %>% 
  html_text() -> amazon_pub_dt_pg_1
head(amazon_pub_dt_pg_1)
```

```{r pub_dt_clean, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
amazon_pub_dt_pg_1 <- as.Date(amazon_pub_dt_pg_1, "%b %d, %Y")
head(amazon_pub_dt_pg_1)
```

---

name: assemble_data

# We Have the Pieces

### Let's assemble the file

---

### Assemble the data

```{r, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}

```

