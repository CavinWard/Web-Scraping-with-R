---
title: "Web Scraping with R & rvest"
subtitle: ""  
author: 
  - "Dr. Matthew Hendrickson"
date: "July 9, 2020"
output:
  revealjs::revealjs_presentation:
    theme: night
    center: true
    widescreen: true
    incremental: true
    fig_width: 9
    fig_height: 3
    df_print: paged
---

```{r setup, include=FALSE, echo = FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE, comment = "#>", collapse = TRUE)
library(tidyverse)
library(robotstxt)
library(rvest)
```


```{r save files, include=FALSE, echo = FALSE, message = FALSE, warning = FALSE, eval = FALSE}
#SAVE BACKUPS OF DATA FOR EASE OF COMPILATION
#write.table(amazon_format, "data/format.txt")
#write.table(amazon_price, "data/price.txt")
#write.table(amazon_price_fraction, "data/price_fraction.txt")
#write.table(amazon_price_whole, "data/price_whole.txt")
#write.table(amazon_pub_dt, "data/pub_dt.txt")
#write.table(amazon_rate_n, "data/rate_n.txt")
#write.table(amazon_rating, "data/rating.txt")
#write.table(amazon_titles, "data/titles.txt")
#saveRDS(r_books, "data/r_books.rds")
```



# Topics

1. About Me
2. A Little About Web Scraping
3. Robots.txt
4. HTML & CSS
5. Web Scraping
6. The Setup
7. Scraping the Data
8. Assembling the Data
9. References & Resources





# About Me

<div style="float: left; width: 50%;">
<img src = "images/headshot.png" width="450" height="450">
</div>

<div style="float: left; width: 50%;">
- Social Scientist by Training
     - Psychology & Music `%>%`
     - More Psychology `%>%`
     - Law & Policy
- Professional Experience (13+ years)
     - Higher Education Analyst
     - Independent Consultant
     - Research projects, data analysis, policy development, strategy, analytics pipeline solutions
</div>





# A Little About Web Scraping

"Web scraping is the process of automatically mining data or collecting information from the World Wide Web." -- Wikipedia

Web scraping is a flexible method to extract data from the internet. It can involve extracting numerical or text data.



## Use Cases

There are many uses for web scraping, including but not limited to:

   1. Price monitoring
   2. Sentiment analysis
   3. Time series tracking and analysis
   4. Brand monitoring
   5. Market analysis
   6. Lead generation



# Robots.txt

Always ensure - <strong>PRIOR to scraping</strong> - that you have rights to scrape the website.

This is critical as you can be blocked from sites or even face legal action.



## Robots.txt

Good news! You can easily check with the `robotstxt` package.

```{r robots, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
paths_allowed(paths = c("https://netflix.com/"))
```

This example shows that Netflix does not allow you to scrape their site.





# HTML & CSS
"HTML is the standard markup language for creating Web pages." -- W3Schools

"CSS describes how HTML elements are to be displayed on screen, paper, or in other media." -- W3Schools



## HTML Structure

<img src = "images/html-structure.png">

<p style = "font-size:65%;">Image credit: [Professor Shawn Santo](http://www2.stat.duke.edu/~fl35/teaching/440-19F/decks/webscraping2.html#3)</p>



## HTML Tags

HTML is strucutred with "tags." These tags indicate portions of the page and can be called by their structure.

There are many types of tags - here are some important ones for scraping:

- `<h1>` - header tags
- `<p>` - paragraph elements
- `<ul>` - unordered bulleted list
- `<ol>` - ordered list
- `<li>` - individual list item
- `<div>` - division
- `<table>` - table



## A Little Help with CSS
If you aren't familiar with CSS, extracting parts of a website can be daunting.

[SelectorGadget](https://selectorgadget.com/) is incredibly helpful for this purpose. However, it is only available for Chrome.

<img src = "images/selector_gadget.png">

Another option is to inspect the page elements, which is available for most major browsers, including Chrome, Firefox, as developer tools.





# Web Scraping



## Scraping Methods

HTML - syntax is easier and aligns with HTML tags

XPATH - useful when the node isn't uniquely identified with CSS





# The Setup

Set up the environment to scrap the site.

```{r setup_slide, eval = FALSE}
library(tidyverse)
library(robotstxt)
library(rvest)
```

That's it! These are all the tools you'll need.



### Determine a website to scrape

It only seems appropriate to pull data from Amazon regarding R books

Ensure we can scrape the site

```{r robots_amazon, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
paths_allowed(paths = c("https://amazon.com/"))
```



We are good to scrape!





# Setting the URL

Before you can get started, you must specific the URLs to pass to the function.

```{r amazon_html, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
amazon <- read_html("https://www.amazon.com/s?k=R&i=stripbooks&rh=n%3A283155%2Cn%3A75%2Cn%3A13983&dc&qid=1592086532&rnid=1000&ref=sr_nr_n_1")
```





# Scraping Book Titles

```{r amazon_title, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
amazon %>% 
  html_nodes(".s-line-clamp-2") %>% 
  html_text() -> amazon_titles
head(amazon_titles)
```

The element pulls a number of breaks and blank spaces.

Let's clean this up with `str_trim`.



## The titles have a great deal of white space and breaks (`\n`), these need to be removed

```{r amazon_title_clean, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
amazon_titles <- str_trim(amazon_titles) # Removes leading & training space
head(amazon_titles)
```

This simple function returns cleaned text.





# Scraping the Book Format

```{r format, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
amazon %>% 
  html_nodes("a.a-size-base.a-link-normal.a-text-bold") %>% 
  html_text() %>% 
  str_trim() -> amazon_format
head(amazon_format)
```





# Scraping the Book Price

```{r price_whole, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
amazon %>% 
  html_nodes(".a-price-whole") %>% 
  html_text() -> amazon_price_whole
head(amazon_price_whole)
```

The price structure splits price into two elements. We must pull each and combine them into a single price.



## Scraping (the rest of) the Book Price

```{r price_fraction, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
amazon %>% 
  html_nodes(".a-price-fraction") %>% 
  html_text() -> amazon_price_fraction
head(amazon_price_fraction)
```



## Combine Price Portions

```{r price_total, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
amazon_price <- as.numeric(paste(amazon_price_whole, amazon_price_fraction, sep = ""))
head(amazon_price)
```





# Scraping the Book Rating

```{r rate, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
amazon %>% 
  html_nodes("i.a-icon.a-icon-star-small.a-star-small-4-5.aok-align-bottom") %>% 
  html_text() -> amazon_rating
head(amazon_rating)
```



## Let's trim this into a usable metric

```{r rate_trim, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
amazon_rating <- as.numeric(substr(amazon_rating, 1, 3))
head(amazon_rating)
```





# Scraping the Book Rating Count

We'll run into the same issue as the actual rating. But first, we'll also see a number of cleaning steps are needed.

```{r rate_n, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
amazon %>% 
  html_nodes("div.a-row.a-size-small") %>% 
  html_text() -> amazon_rate_n
head(amazon_rate_n)
```



## Clean up Rating Count

```{r rate_n_trim, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
amazon_rate_n <- str_trim(amazon_rate_n)    # trim \n & ' '
amazon_rate_n <- str_sub(amazon_rate_n, -5) # keep last 5 characters
amazon_rate_n <- str_trim(amazon_rate_n)    # trim leading spaces
amazon_rate_n <- as.numeric(amazon_rate_n)
head(amazon_rate_n)
```





# Scraping the Book Publication Date

```{r pub_dt, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
amazon %>% 
  html_nodes("span.a-size-base.a-color-secondary.a-text-normal") %>% 
  html_text() -> amazon_pub_dt
head(amazon_pub_dt)
```



## We need to convert this to a date to allow easier analysis

```{r pub_dt_clean, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
amazon_pub_dt <- as.Date(amazon_pub_dt, "%b %d, %Y")
head(amazon_pub_dt)
```





# We Have the Pieces

Let's assemble the file!

1. Titles
2. Formats
3. Prices
4. Ratings
5. Rating Counts
6. Publication Date



## Let's Check the Scrapes

```{r uneven_counts, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
length(amazon_titles)
length(amazon_format)
length(amazon_price)
length(amazon_rating)
length(amazon_rate_n)
length(amazon_pub_dt)
```



## Wait! What?!?

An issue with scraping is sometimes you get an uneven number of records due to missing data elements.

We can fix this (manually)!





# Fixing the Scrapes



## Titles

All titles were populated and scraped accurately. However, due to multiple formats, these records must be repeated to fill the dataframe.

```{r title_missing, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
amazon_titles %>% 
  append(values = amazon_titles[16], after = 16) %>% 
  append(values = amazon_titles[15], after = 15) %>% 
  append(values = amazon_titles[14], after = 14) %>% 
  append(values = amazon_titles[13], after = 13) %>% 
  append(values = amazon_titles[12], after = 12) %>% 
  append(values = amazon_titles[11], after = 11) %>% 
  append(values = amazon_titles[11], after = 11) %>% 
  append(values = amazon_titles[10], after = 10) %>% 
  append(values = amazon_titles[9], after = 9) %>% 
  append(values = amazon_titles[8], after = 8) %>% 
  append(values = amazon_titles[7], after = 7) %>% 
  append(values = amazon_titles[6], after = 6) %>% 
  append(values = amazon_titles[6], after = 6) %>% 
  append(values = amazon_titles[5], after = 5) %>% 
  append(values = amazon_titles[5], after = 5) %>% 
  append(values = amazon_titles[4], after = 4) %>% 
  append(values = amazon_titles[4], after = 4) %>% 
  append(values = amazon_titles[3], after = 3) %>% 
  append(values = amazon_titles[2], after = 2) %>% 
  append(values = amazon_titles[1], after = 1) -> amazon_titles
length(amazon_titles)
```



## Formats

Nothing needed here!

```{r format_missing, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
length(amazon_format)
```



## Prices

Nothing needed here!

```{r price_missing, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
length(amazon_price)
```



## Ratings

Some books do not have ratings. A book only has one rating even if it has multiple formats.

For example, the 5th and 7th book do not have ratings. For some reason, the 6th, 13th, 14th, and 16th book ratings were not captured.

We must also account for multiple formats.

```{r rate_missing, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
amazon_rating %>% 
  append(values = NA, after = 4) %>%   #  4th - no rating
  append(values = 4.8, after = 5) %>%  #  6th - missing rating
  append(values = NA, after = 6) %>%   #  7th - no rating
  append(values = 4.2, after = 12) %>% # 13th - missing rating
  append(values = 3.9, after = 13) %>% # 14th - missing rating
  append(values = 3.8, after = 14) -> amazon_rating
length(amazon_rating)
```



## Ratings

Like titles, the ratings need to be repeated to show on the correct row.

All titles were populated and scraped accurately. However, due to multiple formats, these records must be repeated to fill the dataframe.

```{r rate_missing_repeat, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
amazon_rating %>% 
  append(values = amazon_rating[16], after = 16) %>% 
  append(values = amazon_rating[15], after = 15) %>% 
  append(values = amazon_rating[14], after = 14) %>% 
  append(values = amazon_rating[13], after = 13) %>% 
  append(values = amazon_rating[12], after = 12) %>% 
  append(values = amazon_rating[11], after = 11) %>% 
  append(values = amazon_rating[11], after = 11) %>% 
  append(values = amazon_rating[10], after = 10) %>% 
  append(values = amazon_rating[9], after = 9) %>% 
  append(values = amazon_rating[8], after = 8) %>% 
  append(values = amazon_rating[7], after = 7) %>% 
  append(values = amazon_rating[6], after = 6) %>% 
  append(values = amazon_rating[6], after = 6) %>% 
  append(values = amazon_rating[5], after = 5) %>% 
  append(values = amazon_rating[5], after = 5) %>% 
  append(values = amazon_rating[4], after = 4) %>% 
  append(values = amazon_rating[4], after = 4) %>% 
  append(values = amazon_rating[3], after = 3) %>% 
  append(values = amazon_rating[2], after = 2) %>% 
  append(values = amazon_rating[1], after = 1) -> amazon_rating
length(amazon_rating)
```




## Rating Counts

Not all titles have a rating, specifically 5 and 7

We must also account for multiple formats.

```{r rate_n_missing, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
amazon_rate_n %>% 
  append(values = NA, after = 4) %>% 
  append(values = NA, after = 6) -> amazon_rate_n
length(amazon_rate_n)
```



## Rating Counts

We must also account for multiple formats.

```{r rate_n_missing_repeat, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
amazon_rate_n %>% 
  append(values = amazon_rate_n[16], after = 16) %>% 
  append(values = amazon_rate_n[15], after = 15) %>% 
  append(values = amazon_rate_n[14], after = 14) %>% 
  append(values = amazon_rate_n[13], after = 13) %>% 
  append(values = amazon_rate_n[12], after = 12) %>% 
  append(values = amazon_rate_n[11], after = 11) %>% 
  append(values = amazon_rate_n[11], after = 11) %>% 
  append(values = amazon_rate_n[10], after = 10) %>% 
  append(values = amazon_rate_n[9], after = 9) %>% 
  append(values = amazon_rate_n[8], after = 8) %>% 
  append(values = amazon_rate_n[7], after = 7) %>% 
  append(values = amazon_rate_n[6], after = 6) %>% 
  append(values = amazon_rate_n[6], after = 6) %>% 
  append(values = amazon_rate_n[5], after = 5) %>% 
  append(values = amazon_rate_n[5], after = 5) %>% 
  append(values = amazon_rate_n[4], after = 4) %>% 
  append(values = amazon_rate_n[4], after = 4) %>% 
  append(values = amazon_rate_n[3], after = 3) %>% 
  append(values = amazon_rate_n[2], after = 2) %>% 
  append(values = amazon_rate_n[1], after = 1) -> amazon_rate_n
length(amazon_rate_n)
```



## Publication Date

One last time to create extra rows due to multiple book formats.

```{r pub_dt_missing, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
amazon_pub_dt %>% 
  append(values = amazon_pub_dt[16], after = 16) %>% 
  append(values = amazon_pub_dt[15], after = 15) %>% 
  append(values = amazon_pub_dt[14], after = 14) %>% 
  append(values = amazon_pub_dt[13], after = 13) %>% 
  append(values = amazon_pub_dt[12], after = 12) %>% 
  append(values = amazon_pub_dt[11], after = 11) %>% 
  append(values = amazon_pub_dt[11], after = 11) %>% 
  append(values = amazon_pub_dt[10], after = 10) %>% 
  append(values = amazon_pub_dt[9], after = 9) %>% 
  append(values = amazon_pub_dt[8], after = 8) %>% 
  append(values = amazon_pub_dt[7], after = 7) %>% 
  append(values = amazon_pub_dt[6], after = 6) %>% 
  append(values = amazon_pub_dt[6], after = 6) %>% 
  append(values = amazon_pub_dt[5], after = 5) %>% 
  append(values = amazon_pub_dt[5], after = 5) %>% 
  append(values = amazon_pub_dt[4], after = 4) %>% 
  append(values = amazon_pub_dt[4], after = 4) %>% 
  append(values = amazon_pub_dt[3], after = 3) %>% 
  append(values = amazon_pub_dt[2], after = 2) %>% 
  append(values = amazon_pub_dt[1], after = 1) -> amazon_pub_dt
length(amazon_pub_dt)
```



## One More Time!

```{r even_counts, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
length(amazon_titles)
length(amazon_format)
length(amazon_price)
length(amazon_rating)
length(amazon_rate_n)
length(amazon_pub_dt)
```





# (Finally) Assemble the Data

```{r, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
#r_books <- tibble(title = amazon_titles,
#                  text.format = amazon_format,
#                  price = amazon_price,
#                  rating = amazon_rating,
#                  num.ratings = amazon_rate_n,
#                  publication.date = amazon_pub_dt)
#head(r_books)
```





# Thank you
<img src = "images/twitter.png" width="30" height="30">  
[\@mjhendrickson](https://twitter.com/mjhendrickson)

<img src = "images/linkedin.png" width="30" height="30">  
[matthewjhendrickson](https://www.linkedin.com/in/matthewjhendrickson/)

<img src = "images/github.png" width="30" height="30">  
[mjhendrickson](https://github.com/mjhendrickson)

</br>

[Web Scraping in R & rvest repo](https://github.com/mjhendrickson/Web-Scraping-with-R)

This talk is freely distributed under the MIT License.





# References & Resources

- Bauer V (2016). "Introduction to Web Scraping in R: Very Applied Methods Workgoup." [https://stanford.edu/~vbauer/files/teaching/VAMScrapingSlides.html](https://stanford.edu/~vbauer/files/teaching/VAMScrapingSlides.html).
- University of Cincinnati (2018). "UC Business Analytics R Programming Guide." Specifically the portion of scraping. [https://uc-r.github.io/](https://uc-r.github.io/).
- Dataquest (no date). "Tutorial: Web Scraping in R with rvest." [https://www.dataquest.io/blog/web-scraping-in-r-rvest/](https://www.dataquest.io/blog/web-scraping-in-r-rvest/).
- Im J (2019). "Web Scraping Product Data in R with rvest and purrr." [https://www.business-science.io/code-tools/2019/10/07/rvest-web-scraping.html](https://www.business-science.io/code-tools/2019/10/07/rvest-web-scraping.html).
- Kaushik S (2017). "Beginner's Guide on Web Scraping in R (using rvest) with hands-on example." [https://www.analyticsvidhya.com/blog/2017/03/beginners-guide-on-web-scraping-in-r-using-rvest-with-hands-on-knowledge/](https://www.analyticsvidhya.com/blog/2017/03/beginners-guide-on-web-scraping-in-r-using-rvest-with-hands-on-knowledge/).



## References & Resources continued

- Perceptive Analytics on KDnuggets (2018). "A Primer on Web Scraping in R." [https://www.kdnuggets.com/2018/01/primer-web-scraping-r.html](https://www.kdnuggets.com/2018/01/primer-web-scraping-r.html).
- Rsquared Academy (2019). "Practical Introduction to Web Scraping in R." [https://blog.rsquaredacademy.com/web-scraping/](https://blog.rsquaredacademy.com/web-scraping/).
- W3Schools (no date). "CSS Introduction." [https://www.w3schools.com/css/css_intro.asp](https://www.w3schools.com/css/css_intro.asp).
- W3Schools (no date). "HTML Introduction." [https://www.w3schools.com/html/html_intro.asp](https://www.w3schools.com/html/html_intro.asp).
- W3Schools (no date). "XPath Syntax." [https://www.w3schools.com/xml/xpath_syntax.asp](https://www.w3schools.com/xml/xpath_syntax.asp).
- Wikipedia (2020). "Web scraping." [https://en.wikipedia.org/wiki/Web_scraping](https://en.wikipedia.org/wiki/Web_scraping).