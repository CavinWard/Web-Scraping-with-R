<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Web Scraping in R</title>
    <meta charset="utf-8" />
    <meta name="author" content="Dr. Matthew Hendrickson" />
    <meta name="date" content="2020-06-16" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Web Scraping in R
### Dr. Matthew Hendrickson
### 2020-06-16

---






name: fix

# ITEMS TO FIX:

1. Author
2. Rating Count (works, clean it up)
3. Scraping Methods
4. Data Assembly
5. A Little About Web Scraping
6. Multiple format &amp; price entries

---

name: topics

# Topics

### Ensure these are updated

1. About Me
2. A Little About Web Scraping
3. Robots.txt
4. HTML Structure
5. A Little Help with CSS
6. Scraping Methods (HTML &amp; XPATH)
7. The Setup
8. Scraping the Data
9. Assembling the Data

---

name: about_me

# About Me

- Social Scientist by Training
     - Psychology &amp; Music `%&gt;%`
     - More Psychlogy `%&gt;%`
     - Law &amp; Policy
- Higher Education Analyst by Trade
- R User by Stumbling
     - Excel `%&gt;%`
     - SPSS GUI `%&gt;%`
     - SPSS Syntax `%&gt;%`
     - SQL `%&gt;%`
     - R

---

name: web_scraping_intro

# A Little About Web Scraping

1. Purpose

Web scraping is a flexible method to extract data from the internet. It can involve extracting numerical or text data.

2. Use Cases

There are many uses for web scraping, inlcuding but not limited it:
   a. Price monitoring
   b. Sentiment analysis
   c. Time series tracking and analysis

3. Robots File

Always ensure - PRIOR to scraping - that you have rights to scrape the website. This is critical as you can be blocked from sites or even face legal action. This can easily be accomplished with the `robotstxt` package.

---

name: robots_txt

# Robots.txt

##### Always ensure you check the robots.txt file! This assures you are not breaking the terms of service by scraping the site.


```r
paths_allowed(paths = c("https://netflix.com/"))
```

```
## [1] FALSE
```

This example shows that Netflix does not allow you to scrape their site.

---

name: html_structure
class: inverse, center, middle

# HTML

### Basic Structure

---

name: html_diagram
class: inverse, center, middle

background-image: url(web-scraping-with-r_files/html-structure.png)

???

Image credit: [Professor Shawn Santo](http://www2.stat.duke.edu/~fl35/teaching/440-19F/decks/webscraping2.html#3)

---

name: selector_gadget

# A Little Help with CSS

If you aren't familiar with CSS, extracting parts of a website can be daunting.

SelectorGadget is incredibly helpful for this purpose.

&lt;https://selectorgadget.com/&gt;

* This is a Chrome only extension. Another option is to inspect the page elements.


---

name: scraping_header
class: inverse, center, middle

# Web Scraping

---

name: scraping_methods

# Scraping Methods

1. HTML
2. XPATH

---

name: setup

Set up the environment to scrap the site.


```r
library(tidyverse)
library(robotstxt)
library(rvest)
```

That's it! These are all the tools you'll need.

---

name: scraping_robots

# Determine a website to scrape

### It only seems appropriate to pull data from Amazon regarding R books

##### Ensure we can scrape the site


```r
paths_allowed(paths = c("https://amazon.com/"))
```

```
## [1] TRUE
```

We are good to scrape!

---

name: scraping_amazon_url

# Setting the URLs

### Before you can get started, you must specific the URLs to pass to the function.


```r
amazon &lt;- read_html("https://www.amazon.com/s?k=R&amp;i=stripbooks&amp;rh=n%3A283155%2Cn%3A75%2Cn%3A13983&amp;dc&amp;qid=1592086532&amp;rnid=1000&amp;ref=sr_nr_n_1")
# amazon_pg_2 &lt;- read_html("https://www.amazon.com/s?k=R&amp;i=stripbooks&amp;rh=n%3A283155%2Cn%3A75%2Cn%3A13983&amp;dc&amp;page=2&amp;qid=1592086539&amp;rnid=1000&amp;ref=sr_pg_2")
```

---

name: scraping_amazon_titles

### Scraping Book Titles


```r
amazon %&gt;% 
  html_nodes(".s-line-clamp-2") %&gt;% 
  html_text() -&gt; amazon_titles
head(amazon_titles)
```

```
## [1] "\n    \n    \n        \n\n\n\n\n\n    \n        \n            \n                R for Data Science: Import, Tidy, Transform, Visualize, and Model Data\n            \n        \n        \n    \n\n\n    \n"                              
## [2] "\n    \n    \n        \n\n\n\n\n\n    \n        \n            \n                Interactive Web-Based Data Visualization with R, plotly, and shiny (Chapman &amp; Hall/CRC The R Series)\n            \n        \n        \n    \n\n\n    \n"
## [3] "\n    \n    \n        \n\n\n\n\n\n    \n        \n            \n                The Book of R: A First Course in Programming and Statistics\n            \n        \n        \n    \n\n\n    \n"                                         
## [4] "\n    \n    \n        \n\n\n\n\n\n    \n        \n            \n                R Graphics Cookbook: Practical Recipes for Visualizing Data\n            \n        \n        \n    \n\n\n    \n"                                         
## [5] "\n    \n    \n        \n\n\n\n\n\n    \n        \n            \n                Discovering Statistics Using R\n            \n        \n        \n    \n\n\n    \n"                                                                      
## [6] "\n    \n    \n        \n\n\n\n\n\n    \n        \n            \n                Advanced R, Second Edition (Chapman &amp; Hall/CRC The R Series)\n            \n        \n        \n    \n\n\n    \n"
```

The element pulls a number of breaks and blank spaces.

Let's clean this up with `str_trim`.

---

name: scraping_amazon_titles_clean

### The titles have a great deal of white space and breaks (\n), these need to be removed


```r
amazon_titles &lt;- str_trim(amazon_titles) # Removes leading &amp; training space
head(amazon_titles)
```

```
## [1] "R for Data Science: Import, Tidy, Transform, Visualize, and Model Data"                              
## [2] "Interactive Web-Based Data Visualization with R, plotly, and shiny (Chapman &amp; Hall/CRC The R Series)"
## [3] "The Book of R: A First Course in Programming and Statistics"                                         
## [4] "R Graphics Cookbook: Practical Recipes for Visualizing Data"                                         
## [5] "Discovering Statistics Using R"                                                                      
## [6] "Advanced R, Second Edition (Chapman &amp; Hall/CRC The R Series)"
```

This simple function returns cleaned text.

Unfortunately, there are mutilple formats and prices for each title. Here's we'll create additional title records for creating the dataset.

---

name: scraping_amazon_titles_duplicate


```r
#amazon_titles %&gt;% 
  #append(values = NA, after = 1) -&gt; amazon_titles
#head(amazon_titles)
```

This structure will serve our needs for future steps.

---

name: scraping_amazon_author

### Get the book author(s)


```r
amazon %&gt;% 
#  html_nodes("a.a-size-base.a-link-normal") %&gt;% 
  html_nodes("div.a-row.a-size-base.a-color-secondary") %&gt;% 
  html_text() %&gt;% 
  str_trim() -&gt; amazon_authors
head(amazon_authors)
```

```
## [1] "by \n\n\n\n\n\n    \n        \n        \n            Hadley Wickham\n        \n    \n\n and \n\n\n\n\n\n    \n        \n        \n            Garrett Grolemund\n        \n    \n\n | Jan 10, 2017"
## [2] "Get 3 for the price of 2"                                                                                                                                                                          
## [3] "Get it as soon as Thu, Jun 18\n\n\n\n\n\n    FREE Shipping by Amazon"                                                                                                                              
## [4] "More Buying Choices$32.99\n\n\n\n\n\n    \n        \n        \n            (38 used &amp; new offers)"                                                                                                 
## [5] "by \n\n\n\n\n\n    \n        \n        \n            Carson Sievert\n        \n    \n\n | Jan 21, 2020"                                                                                            
## [6] "Get it as soon as Thu, Jun 18\n\n\n\n\n\n    FREE Shipping by Amazon"
```

We run into issues here due to the element in which authors are placed.

We also need to split the author fields.

---

name: scraping_amazon_format

### Get the book format


```r
amazon %&gt;% 
  html_nodes("a.a-size-base.a-link-normal.a-text-bold") %&gt;% 
  html_text() %&gt;% 
  str_trim() -&gt; amazon_format
head(amazon_format)
```

```
## [1] "Paperback" "Kindle"    "Paperback" "Kindle"    "Hardcover" "Paperback"
```

---

name: scraping_amazon_price

### Get the book price


```r
amazon %&gt;% 
  html_nodes(".a-price-whole") %&gt;% 
  html_text() -&gt; amazon_price_whole
head(amazon_price_whole)
```

```
## [1] "39."  "24."  "71."  "18."  "164." "33."
```

The price structure splits price into two elements. We must pull each and combine them into a single price.

##### Get (the rest of) the book price


```r
amazon %&gt;% 
  html_nodes(".a-price-fraction") %&gt;% 
  html_text() -&gt; amazon_price_fraction
head(amazon_price_fraction)
```

```
## [1] "49" "99" "95" "58" "57" "04"
```

##### Combine price portions


```r
amazon_price &lt;- as.numeric(paste(amazon_price_whole, amazon_price_fraction, sep = ""))
head(amazon_price)
```

```
## [1]  39.49  24.99  71.95  18.58 164.57  33.04
```

---

name: scraping_amazon_rating

### Get the book rating


```r
amazon %&gt;% 
  html_nodes("i.a-icon.a-icon-star-small.a-star-small-4-5.aok-align-bottom") %&gt;% 
  html_text() -&gt; amazon_rating
head(amazon_rating)
```

```
## [1] "4.7 out of 5 stars" "4.3 out of 5 stars" "4.7 out of 5 stars"
## [4] "4.5 out of 5 stars" "4.3 out of 5 stars" "4.7 out of 5 stars"
```

Let's trim this into a usable metric.


```r
amazon_rating &lt;- as.numeric(substr(amazon_rating, 1, 3))
head(amazon_rating)
```

```
## [1] 4.7 4.3 4.7 4.5 4.3 4.7
```

---

name: scraping_amazon_rating_missing

Another issue with ratings is that not all titles have ratings. We must adjust for this.

I'll do this manually by appending NA where ratings are missing.


```r
amazon_rating %&gt;% 
  append(values = NA, after = 1) %&gt;% 
  append(values = NA, after = 11) -&gt; amazon_rating
head(amazon_rating)
```

```
## [1] 4.7  NA 4.3 4.7 4.5 4.3
```

---

name: scraping_amazon_num_ratings

### Get the book rating count

We'll run into the same issue as the actual rating. But first, we'll also see a number of cleaning steps are needed.


```r
amazon %&gt;% 
#  html_nodes("span.a-size-base") %&gt;% 
  html_nodes("div.a-row.a-size-small") %&gt;% 
  html_text() -&gt; amazon_rate_n
amazon_rate_n &lt;- str_trim(amazon_rate_n) # trim
#amazon_rate_n &lt;- str_sub(amazon_rate_n, regex(?&lt;=\s))
amazon_rate_n &lt;- str_sub(amazon_rate_n, -5) # keep last 5 characters
amazon_rate_n &lt;- str_trim(amazon_rate_n) # trim leading spaces
amazon_rate_n &lt;- as.numeric(amazon_rate_n)
head(amazon_rate_n)
```

```
## [1] 422  75  13 254  31  49
```

---

name: scraping_amazon_num_ratings_missing


```r
amazon_rate_n %&gt;% 
  append(values = NA, after = 1) %&gt;% 
  append(values = NA, after = 11) -&gt; amazon_rate_n
head(amazon_rate_n)
```

```
## [1] 422  NA  75  13 254  31
```

---
name: scraping_amazon_pub_date

### Get the book publication date


```r
amazon %&gt;% 
  html_nodes("span.a-size-base.a-color-secondary.a-text-normal") %&gt;% 
  html_text() -&gt; amazon_pub_dt
head(amazon_pub_dt)
```

```
## [1] "Jan 10, 2017" "Jan 21, 2020" "Jul 16, 2016" "Nov 30, 2018" "Apr 5, 2012" 
## [6] "May 30, 2019"
```

We need to convert this to a date to allow easier analysis.


```r
amazon_pub_dt &lt;- as.Date(amazon_pub_dt, "%b %d, %Y")
head(amazon_pub_dt)
```

```
## [1] "2017-01-10" "2020-01-21" "2016-07-16" "2018-11-30" "2012-04-05"
## [6] "2019-05-30"
```

---

name: assemble_data

# We Have the Pieces

### Let's assemble the file

---

### Assemble the data


```r
#r_books &lt;- tibble(title = amazon_titles,
#                  author = amazon_authors,
#                  text.format = amazon_format,
#                  price = amazon_price,
#                  rating = amazon_rating,
#                  num.ratings = amazon_rate_n,
#                  publication.date = amazon_pub_dt)
#head(r_books)
```
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
